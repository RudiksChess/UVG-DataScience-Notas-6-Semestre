{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovpZyIhNIgoq"
   },
   "source": [
    "# Generación de textos con Redes Neuronales\n",
    "\n",
    "En este NoteBook se creará una red que pueda generar texto.  Se verá como lo hacer caracter por caracter.  En el siguiente enlace se encuentra un artículo interesante sobre esto: http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "Se ha organizado el proceso en \"pasos\" para que fácilmente se pueda utilizar con cualquier conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00mwlQwloO5_"
   },
   "outputs": [],
   "source": [
    "# SOLO PARA USUARIOS DE GOOGLE COLLAB\n",
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBd69MDEm4rF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDbPtshnm4rL"
   },
   "outputs": [],
   "source": [
    "# IGNORAR EL CONTENIDO DE ESTA CELDA\n",
    "# tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kycWuRI9oaSP"
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apj1Chkdm4rS"
   },
   "source": [
    "## Paso 1: Los Datos\n",
    "\n",
    "Se puede bajar cualquier texto en forma gratuita desde este enlace:   www.gutenberg.org/\n",
    "\n",
    "Para este ejercicio se han escogido todas las obras de Shakespear. Los datos ya han sido descargados.  Esta decisión se basó en dos razones:\n",
    "\n",
    "1. Es un cuerpo enorme de texto, generalmente se recomiento que se tenga una fuente de al menos 1 millón de caracteres para lograr una generación de texto realista.\n",
    "\n",
    "2. Tiene un estilo muy distinctivo.  Como el texto está en inglés antiguo, y está formateado en el estilo de una obra de teatro, será muy obvio si el modelo puede producir resultados similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pD_55cOxLkAb"
   },
   "outputs": [],
   "source": [
    "direccion_archivo = 'shakespeare.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aavnuByVymwK"
   },
   "outputs": [],
   "source": [
    "texto = open(direccion_archivo, 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Duhg9NrUymwO"
   },
   "outputs": [],
   "source": [
    "print(texto[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXUmR627m4rd"
   },
   "source": [
    "### Ver cuáles son los caracteres únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlCgQBRVymwR"
   },
   "outputs": [],
   "source": [
    "# Los caracteres únicos en el archivo\n",
    "vocabulario = sorted(set(texto))\n",
    "print(vocabulario)\n",
    "len(vocabulario)  #importante tener en mente para trabajar la capa Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNnrKn_lL-IJ"
   },
   "source": [
    "## Paso 2: Procesamiento de Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFjSVAlWzf-N",
    "tags": []
   },
   "source": [
    "### Vectorización de Texto\n",
    "\n",
    "Sabemos que una red neuronal no puede recibir datos en cadenas, es necesario asignar un número a cada caracter.  Se crearán dos diccionarios que puedan ir de índice numérico a caracter, y de caracter a índice numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IalZLbvOzf-F"
   },
   "outputs": [],
   "source": [
    "caract_a_indice = {u:i for i, u in enumerate(vocabulario)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmmP5iCwm4rp"
   },
   "outputs": [],
   "source": [
    "caract_a_indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30ZYaWAOm4rt"
   },
   "outputs": [],
   "source": [
    "indice_a_caract = np.array(vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6JPOWwJm4rz"
   },
   "outputs": [],
   "source": [
    "indice_a_caract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fhOqV0lm4r2"
   },
   "outputs": [],
   "source": [
    "texto_codificado = np.array([caract_a_indice[c] for c in texto])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axOX7rFom4r5"
   },
   "outputs": [],
   "source": [
    "texto_codificado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZfqhkYCymwX",
    "tags": []
   },
   "source": [
    "Ahora tenemos un mapeo que nos permite ir desde caracteres a numérico y viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFs1Uza-m4r9"
   },
   "outputs": [],
   "source": [
    "muestra = texto[:500]\n",
    "muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gIqUCK5Am4sB"
   },
   "outputs": [],
   "source": [
    "texto_codificado[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbmsf23Bymwe",
    "tags": []
   },
   "source": [
    "## Paso 3: Crear Tandas\n",
    "\n",
    "En general, lo que se trata de hacer es lograr que el modelo prediga el siguiente caracter de alta probabilidad, dados una secuencia histórica de caracteres.  \n",
    "\n",
    "El usuario debe decidir qué tan larga va a ser esa secuencia histórica.  Una secuencia muy corta y no se tiene suficiente información (e.g. dados la letra \"a\", cuál es el siguiente caracter).  Una secuencia muy larga y el entrenamiento será muy largo y lo más probable es que *sobre ajuste* a caracteres secuenciales que son irrelevantes a caracters más lejanos.\n",
    "\n",
    "Si bien no hay una selección de longitud de secuencia correcta, es importante considerar al texto mismo, que tan largo son las frases normales que tiene, y una idea razonable sobre qué caracteres/palabras son relevantes etre sí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pAvUYFk7m4sF"
   },
   "outputs": [],
   "source": [
    "print(texto[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D45OYgOfm4sJ"
   },
   "outputs": [],
   "source": [
    "linea = \"From fairest creatures we desire increase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dKiEVN8m4sL"
   },
   "outputs": [],
   "source": [
    "len(linea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "olX67f6-m4sP"
   },
   "outputs": [],
   "source": [
    "parte_estrofa = \"\"\"From fairest creatures we desire increase,\n",
    "  That thereby beauty's rose might never die,\n",
    "  But as the riper should by time decease,\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qal7MQnqm4sQ"
   },
   "outputs": [],
   "source": [
    "len(parte_estrofa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "### Secuencias de entrenamiento\n",
    "\n",
    "El texto actual será la secuencia de texto desplazado hacia adelante en un caracter. Por ejemplo:\n",
    "\n",
    "\n",
    "Secuencia Entrante: \"Hola mi nom\"\n",
    "Secuencia Saliente: \"ola mi nomb\"\n",
    "\n",
    "\n",
    "Se puede usar la función `tf.data.Dataset.from_tensor_slices` para  convertir un vector de texto a un flujo de indices de caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0UHJDA39zf-O"
   },
   "outputs": [],
   "source": [
    "# Viendo que una línea es aprox 40 caracteres y que Shakespeare\n",
    "#   utiliza una rima, mas o menos, a cada 3 líneas, seleccionamos:\n",
    "long_secuencia = 120  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VRSK4cOm4sZ"
   },
   "outputs": [],
   "source": [
    "num_total_secuencias = len(texto)//(long_secuencia + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtW0jbbvm4sc"
   },
   "outputs": [],
   "source": [
    "num_total_secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ciatnowvm4se"
   },
   "outputs": [],
   "source": [
    "# Crear las secuencias de entrenamiento\n",
    "conjunto_caract = tf.data.Dataset.from_tensor_slices(texto_codificado)\n",
    "type(conjunto_caract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUoi5zAQzdnF"
   },
   "outputs": [],
   "source": [
    "for i in conjunto_caract.take(500):\n",
    "     print(indice_a_caract[i.numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZSYAcQV8OGP"
   },
   "source": [
    "El método de tandas convierte estas llamadas de caracteres individuales a secuencias que se pueden alimentar como una tanda.  Se utiliza long_secuencia + 1 debido a la indización empezando en cero.  Esto es lo que *drop_remainder* quiere decir: \n",
    "\n",
    "\n",
    "drop_remainder: (Opcional) Un escalar `tf.Tensor` de tipo `tf.bool`, que representa\n",
    "    si la última tanda debe ser \"botada\" en caso tenga menos de \n",
    "    `batch_size` elementos; el comportamiento normal es no \"botar\" la tanda menor.\n",
    "    \n",
    "Esto es debido a la división de enteros que se hizo para calcular el número de secuencias...pueden quedar algunos residuos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4hkDU3i7ozi"
   },
   "outputs": [],
   "source": [
    "secuencias = conjunto_caract.batch(long_secuencia + 1, \n",
    "                                   drop_remainder = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbLcIPBj_mWZ"
   },
   "source": [
    "Ahora que ya se tienen las secuencias, se ejecutarán los siguientes pasos para crear las secuencuas de texto meta:\n",
    "\n",
    "1. Obtener la secuencia de texto entrante\n",
    "2. Asignar la secuencia de texto meta como la secuencia de texto entrante, desplazada por un paso hacia adelante\n",
    "3. Agruparlos como una tupla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [],
   "source": [
    "def crear_secuencias_meta(sec):\n",
    "    texto_entrada = sec[:-1]\n",
    "    texto_meta = sec[1:]\n",
    "    return texto_entrada, texto_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HszljTg8m4so"
   },
   "outputs": [],
   "source": [
    "# El conjunto de datos final que se alimentará a la red\n",
    "datos = secuencias.map(crear_secuencias_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkPa7AMrm4sq"
   },
   "outputs": [],
   "source": [
    "for texto_entrada, texto_meta in datos.take(1):\n",
    "    print(texto_entrada.numpy())\n",
    "    print(''.join(indice_a_caract[texto_entrada.numpy()]))\n",
    "    print('\\n')\n",
    "    print(texto_meta.numpy())\n",
    "    # Hay espacio en blanco extra!\n",
    "    print(''.join(indice_a_caract[texto_meta.numpy()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJdfPmdqzf-R"
   },
   "source": [
    "### Generar las tandas de entrenamiento\n",
    "\n",
    "Ahora que se tienen las secuencias, se crearán las tandas.  Se \"barajean\" estas secuencias en un orden al azar, para que el modelo no se sobreajuste a cualquier sección de texto, pero que pueda generar caracteres dados cualquier texto \"semilla\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2pGotuNzf-S"
   },
   "outputs": [],
   "source": [
    "tamanio_tanda = 128\n",
    "\n",
    "# Tamaño del espacio \"Buffer\" para barajear los datos con el fin \n",
    "#   de que no intente barajear toda la secuencie en memoria.  En \n",
    "#   vez, mantiene un  \"buffer\" en el cual barajea elementos\n",
    "tamanio_buffer = 10000\n",
    "\n",
    "datos = datos.shuffle(tamanio_buffer).batch(tamanio_tanda, \n",
    "                                            drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmcCALymm4su"
   },
   "outputs": [],
   "source": [
    "datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "## Paso 4: Crear el Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8gPwEjRzf-Z"
   },
   "source": [
    "Se usará un modelo basado en LSTM con unas características extra, incluyendo una capa de incrustación \"embedding\" para empezar, y **dos** capas LSTM layers. Esta arquitectura de modelo se basa en [DeepMoji](https://deepmoji.mit.edu/) y la fuente original del código puede ser encontrada [aquí](https://github.com/bfelbo/DeepMoji).\n",
    "\n",
    "La capa de incrustación servirá como la capa de entrada.  Escencialmente, esta crea una tabla de consulta que mapea los índices numéricos de cada caracter a un vector con \"dim_incrust\" número de dimensiones.  Como es de imaginar, entre más grande este tamaño de incrustación, más complejo el entrenamiento.  Esto es similar a la idea detrás de word2vec, donde las palabras se mapean a algún espacio n-dimensional. Hacer la incrustación antes de alimentar directamente al LSTM, generalmente conlleva a resultados mas realistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "# Longitud del vocabulario en caracteres\n",
    "long_vocab = len(vocabulario)\n",
    "\n",
    "# Dimensionamiento de la incrustación.  Se trata de que sea de\n",
    "#    orden aproximado a long_vocab.  No es deseable que sea mucho \n",
    "#    más grande ya que el incremento en dimensiones afecta el \n",
    "#    tiempo de ejecución\n",
    "dim_incrust = 64\n",
    "\n",
    "# Número de unidades RNN\n",
    "neuronas_rnn = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Atb060h5m4s0"
   },
   "source": [
    "Ahora se creará una función que se adapte fácilmente a variables diferentes como se ha mostrado arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YeRlEXgym4s1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# se puede \"jugar\" con todo tipo de capas\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, GRU\n",
    "\n",
    "# para este ejemplo solo usaremos Dense, Embedding, GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcMbIy-xj-w-"
   },
   "source": [
    "### Configurar la función de pérdida\n",
    "\n",
    "Para la pérdida se utilizará *sparse categorical crossentropy*, que se puede importar de Keras.  Se selecciona esta debido a que las etiquetas están \"one hot encoded\"\n",
    "\n",
    "También se dejará como logits = True, ya que este parámetro se refiere a si las etiquetas están, o no, \"one hot encoded\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoFVGKlNkJfW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sblCzZoslZKH"
   },
   "outputs": [],
   "source": [
    "help(sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5N4Qxbij5gY"
   },
   "source": [
    "https://datascience.stackexchange.com/questions/41921/sparse-categorical-crossentropy-vs-categorical-crossentropy-keras-accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrOOK61Olm1C"
   },
   "outputs": [],
   "source": [
    "# Debido a que \"sparse_categorical_crossentropy\" tiene por default\n",
    "#   \"logits = False\", se necesita una forma de cambiarlo.  Esto se \n",
    "#   hace envolviendo o poniendo un \"wrapper\" al método \n",
    "\n",
    "def perdida_categ_escasa(y_real,y_pred):\n",
    "  return sparse_categorical_crossentropy(y_real, y_pred, \n",
    "                                         from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MtCrdfzEI2N0"
   },
   "outputs": [],
   "source": [
    "def crear_modelo(tamanio_vocab, dim_incrust, neuronas_rnn, \n",
    "                 tamanio_tanda):\n",
    "    \n",
    "    modelo = Sequential()\n",
    "    modelo.add(Embedding(tamanio_vocab, dim_incrust, \n",
    "                         batch_input_shape=[tamanio_tanda, None]))\n",
    "    modelo.add(GRU(neuronas_rnn, return_sequences = True,\n",
    "                   stateful = True, \n",
    "                   recurrent_initializer = 'glorot_uniform'))\n",
    "    \n",
    "    # Capa Final Densa para Predecir\n",
    "    modelo.add(Dense(long_vocab))\n",
    "    modelo.compile(optimizer = 'adam', loss = perdida_categ_escasa) \n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwsrpOik5zhv"
   },
   "outputs": [],
   "source": [
    "modelo = crear_modelo(long_vocab, dim_incrust,\n",
    "                      neuronas_rnn, tamanio_tanda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liXuTFYMm4s6"
   },
   "outputs": [],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "## Paso 5: Entrenar el modelo\n",
    "\n",
    "Antes de desperdiciar mucho tiempo con el modelo, se verifica que todo funcione bien.  Se le alimentará una tanda para asegurar que el modelo predice caracteres al azar, sin entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4ygvfHn-wan"
   },
   "outputs": [],
   "source": [
    "for tanda_muestra_entrada, tanda_muestra_meta in datos.take(1):\n",
    "\n",
    "  # Prededir a partir de una tanda al azar\n",
    "  tanda_muestra_predicciones = modelo(tanda_muestra_entrada)\n",
    "\n",
    "  # Desplegsar las dimensiones de las predicciones\n",
    "  print(tanda_muestra_predicciones.shape, \n",
    "        \" <=== (tamanio_tanda, long_secuencia, long_vocab)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ld8z3LPBAuv"
   },
   "outputs": [],
   "source": [
    "tanda_muestra_predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_achqjT-BGyY"
   },
   "outputs": [],
   "source": [
    "indices_muestreados = tf.random.categorical(tanda_muestra_predicciones[0], \n",
    "                                            num_samples = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWrPFk2nBJX4"
   },
   "outputs": [],
   "source": [
    "indices_muestreados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wi80PQVtBLqj"
   },
   "outputs": [],
   "source": [
    "# Reformatear para que no sea una lista de listas\n",
    "indices_muestreados = tf.squeeze(indices_muestreados, \n",
    "                                 axis = -1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qYkIg00-wjq"
   },
   "outputs": [],
   "source": [
    "indices_muestreados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9-P_XqQ_7wY"
   },
   "outputs": [],
   "source": [
    "print(\"Dado la secuencia de entrada: \\n\")\n",
    "print(\"\".join(indice_a_caract[tanda_muestra_entrada[0]]))\n",
    "print('\\n')\n",
    "print(\"Predicciones del siguiente caracter: \\n\")\n",
    "print(\"\".join(indice_a_caract[indices_muestreados ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAOE4rzuBh7f"
   },
   "source": [
    "Luego de confirmar las dimensiones, se procede a entrenar la red!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYDQjKTlm4s8"
   },
   "outputs": [],
   "source": [
    "epocas = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PJ4OVdBm4s8"
   },
   "outputs": [],
   "source": [
    "modelo.fit(datos, epochs = epocas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## Paso 6: Generar texto\n",
    "\n",
    "Como está ahorita, el modelo solo espera 128 secuencias a la vez.  Se puede crear un modelo que solo espere un tamanio_tanda = 1.  Se puede crear un modelo con este tamanio de tanda, y luego cargar los pesos que se han guardado.  Luego se invoca *.build()* sobre el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYRNG57Govdc"
   },
   "outputs": [],
   "source": [
    "modelo.save('shakespeare_gen.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCoJayFS8H4d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_iXG3VJvEXWM"
   },
   "outputs": [],
   "source": [
    "modelo = crear_modelo(long_vocab, dim_incrust, \n",
    "                      neuronas_rnn, tamanio_tanda=1)\n",
    "\n",
    "modelo.load_weights('shakespeare_gen.h5')\n",
    "\n",
    "modelo.build(tf.TensorShape([1, None]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAX3p7_YEilU"
   },
   "outputs": [],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvuwZBX5Ogfd"
   },
   "outputs": [],
   "source": [
    "def generar_texto(modelo, semilla_inicial, num_caract = 500, temp = 1.0):\n",
    "  '''\n",
    "  modelo: Modelo entrenado para Generar Texto\n",
    "  \n",
    "  semilla_inicial: Texto en formato cadena \"string\" a usar como semilla\n",
    "  num_caract: Número de caracteres a generar\n",
    "\n",
    "  La idea básica de esta función es la de tomar un texto semilla,\n",
    "  formatearlo para que quede en la forma correcta para nuestra red,\n",
    "  luego pasar la secuencia por una iteración conforme se le vayan\n",
    "  agregando los caracteres predichos.  Parecido a lo que se hace\n",
    "  con RNNs y series de tiempo.\n",
    "  '''\n",
    "\n",
    "  # Número de caracteres a generar\n",
    "  num_generar = num_caract\n",
    "\n",
    "  # Vectorización del texto semilla\n",
    "  eval_entrada = [caract_a_indice[s] for s in semilla_inicial]\n",
    "\n",
    "  # Expander para llegar a la forma requerida de tanda\n",
    "  eval_entrada = tf.expand_dims(eval_entrada, 0)\n",
    "\n",
    "  # Lista vacía para acumular el texto generado\n",
    "  texto_generado = []\n",
    "\n",
    "  # La \"temperatura\" afecta la aleatoriedad en el texto resultante\n",
    "  # El término es derivado de entropía/termodinámica.\n",
    "  # La \"temperatura\" se utiliza para afectar la probabilidad de\n",
    "  #    los siguientes caracteres.\n",
    "  # Temperatura mayor == menos sorprendente/ más esperado\n",
    "  # Temperatura meno == más sorprendente / menos esperado\n",
    " \n",
    "  temperatura = temp\n",
    "\n",
    "  # Recordar que aquí tamanio_tanda == 1\n",
    "  modelo.reset_states()\n",
    "\n",
    "  for i in range(num_generar):\n",
    "\n",
    "      # Generar Predicciones\n",
    "      predicciones = modelo(eval_entrada)\n",
    "\n",
    "      # Eliminar la dimensión de la forma de las tandas\n",
    "      predicciones = tf.squeeze(predicciones, 0)\n",
    "\n",
    "      # Usar una distribución categórica para escoger el\n",
    "      #   siguiente caracter\n",
    "      predicciones = predicciones / temperatura\n",
    "      id_predicho = tf.random.categorical(predicciones, \n",
    "                                          num_samples = 1)[-1,0].numpy()\n",
    "\n",
    "      # Pasar el caracter predicho para la siguiente entrada\n",
    "      eval_entrada = tf.expand_dims([id_predicho], 0)\n",
    "\n",
    "      # Transformar de vuelta a una letra\n",
    "      texto_generado.append(indice_a_caract[id_predicho])\n",
    "\n",
    "  return (semilla_inicial + ''.join(texto_generado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bS69SG5D5lwd"
   },
   "outputs": [],
   "source": [
    "print(generar_texto(modelo, \"flower\", num_caract = 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dff5xCHIeEHO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Generar_Texto_con_RNN_colab.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
